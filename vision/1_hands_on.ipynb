{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cdc132b",
   "metadata": {
    "editable": true,
    "id": "2iUXCk7tC1x5",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "# Session 1 : Training your first aircraft classifier with pytorch\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a>&nbsp;| Florient Chouteau | <a href=\"https://supaerodatascience.github.io/deep-learning/\">https://supaerodatascience.github.io/deep-learning/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e560a",
   "metadata": {
    "editable": true,
    "id": "yfn1RtChC1yD",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Intro\n",
    "\n",
    "The objectives of this session is to apply what you learned during [the previous class on Deep Learning](https://supaerodatascience.github.io/deep-learning/) on a real dataset of satellite images.\n",
    "\n",
    "Most of the vocabulary and concepts of Deep Learning and Convolutionnal Neural Network has been defined on the class linked above so you should refer to it.\n",
    "\n",
    "In this session you will:\n",
    "- Train a basic NN on a basic dataset\n",
    "- Plot ROC curve & confusion matrix to diagnose your dataset\n",
    "\n",
    "During session 2 you will be experimenting with harder datasets\n",
    "\n",
    "If you haven't done so, go to the previous notebooks to get a hands on pytorch and CNNs\n",
    "\n",
    "\n",
    "**First steps**\n",
    "- Activate the GPU runtime in colab\n",
    "- Check using `!nvidia-smi` that you detect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3371c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Installation script for torchinfo package\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9831c",
   "metadata": {
    "editable": true,
    "id": "xEo4VpHqC1yF",
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35538d60",
   "metadata": {
    "editable": true,
    "id": "FG3_sWsWC1yH",
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Put your imports here\n",
    "import numpy as np\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249685e6",
   "metadata": {
    "editable": true,
    "id": "1nb7isjuC1yI",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Récupération et exploration du datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e333e",
   "metadata": {
    "editable": true,
    "id": "XLml82VWC1yK",
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "TOY_DATASET_URL = \"https://storage.googleapis.com/fchouteau-isae-deep-learning/toy_cloud_classification_2025.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1139f0",
   "metadata": {
    "editable": true,
    "id": "Shmmb50XC1yK",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "### Image (reminders)\n",
    "\n",
    "A digital image is an image composed of picture elements, also known as pixels, each with finite, discrete quantities of numeric representation for its intensity or gray level that is an output from its two-dimensional functions fed as input by its spatial coordinates denoted with x, y on the x-axis and y-axis, respectively.\n",
    "\n",
    "We represent images as matrixes,\n",
    "\n",
    "Images are made of pixels, and pixels are made of combinations of primary colors (in our case Red, Green and Blue). In this context, images have chanels that are the grayscale image of the same size as a color image, made of just one of these primary colors. For instance, an image from a standard digital camera will have a red, green and blue channel. A grayscale image has just one channel.\n",
    "\n",
    "In geographic information systems, channels are often referred to as raster bands.\n",
    "\n",
    "![img](https://static.packt-cdn.com/products/9781789613964/graphics/e91171a3-f7ea-411e-a3e1-6d3892b8e1e5.png)\n",
    "\n",
    "\n",
    "For the rest of this workshop we will use the following axis conventions for images\n",
    "\n",
    "![conventions](https://storage.googleapis.com/fchouteau-isae-deep-learning/static/image_coordinates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b898ece",
   "metadata": {
    "editable": true,
    "id": "nPa5zHUBC1yN",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "### Downloading the dataset\n",
    "\n",
    "We will be using [numpy datasources](https://docs.scipy.org/doc/numpy/reference/generated/numpy.DataSource.html?highlight=datasources) to download the dataset. DataSources can be local files or remote files/URLs. The files may also be compressed or uncompressed. DataSource hides some of the low-level details of downloading the file, allowing you to simply pass in a valid file path (or URL) and obtain a file object.\n",
    "\n",
    "The dataset is in npz format which is a packaging format where we store several numpy arrays in key-value format\n",
    "\n",
    "Note:\n",
    "If you get an error with the code below run:\n",
    "```python\n",
    "!gsutil -m cp -r gs://isae-deep-learning/toy_aircraft_dataset.npz /tmp/storage.googleapis.com/isae-deep-learning/toy_cloud_classification_2025.npz\n",
    "```\n",
    "in a cell above the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9218c4",
   "metadata": {
    "editable": true,
    "id": "aPxBx-2-C1yP",
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "ds = np.lib.npyio.DataSource(destpath=\"/tmp/\")\n",
    "f = ds.open(TOY_DATASET_URL, \"rb\")\n",
    "\n",
    "toy_dataset = np.load(f)\n",
    "trainval_images = toy_dataset[\"train_images\"]\n",
    "trainval_labels = toy_dataset[\"train_labels\"]\n",
    "test_images = toy_dataset[\"test_images\"]\n",
    "test_labels = toy_dataset[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730e615",
   "metadata": {
    "editable": true,
    "id": "dRMdfPRKC1yR",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "### A bit of data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218af73e",
   "metadata": {
    "editable": true,
    "id": "KLD83Y7vC1yR",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**Q1. Labels counting**\n",
    "\n",
    "a. What is the dataset size ?\n",
    "\n",
    "b. How many images representing cloudy images ?\n",
    "\n",
    "c. How many images representing backgrounds ?\n",
    "\n",
    "d. What are the dimensions (height and width) of the images ? What are the number of channels ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc279c",
   "metadata": {
    "editable": true,
    "id": "5xkrtVx-C1yS",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**Q2. Can you plot at least 8 examples of each label ? In a 4x4 grid ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580074f",
   "metadata": {
    "editable": true,
    "id": "n_fynC7iC1yT",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Here are some examples that help you answer this question. Try them and make your own. A well-understandood dataset is the key to an efficient model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab687e6d",
   "metadata": {
    "editable": true,
    "id": "7XcQrRWKC1yT",
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9168d0",
   "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
