{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqRHyNzdeXaS"
      },
      "source": [
        "# Minimal Transformer: Next Token Prediction\n",
        "\n",
        "In this notebook, we build a minimal decoder-only transformer architecture (similar to GPT) and train it on next token prediction. This follows your previous class on attention mechanisms.\n",
        "\n",
        "**Key differences from encoder-decoder transformers:**\n",
        "- Decoder-only architecture (no encoder)\n",
        "- Causal self-attention (can only attend to previous tokens)\n",
        "- Next token prediction objective\n",
        "- Character-level tokenization for simplicity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl40akxCeXaU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qPu9uTHTeXaU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "print(f'PyTorch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgcbOVzneXaV"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "We keep the model small so it can train quickly in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Qlf2t7UpeXaV"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "class Config:\n",
        "    # Model architecture\n",
        "    d_model = 128          # Embedding dimension\n",
        "    n_heads = 4            # Number of attention heads\n",
        "    n_layers = 4           # Number of transformer blocks\n",
        "    d_ff = 512             # Feed-forward dimension\n",
        "    dropout = 0.1          # Dropout rate\n",
        "\n",
        "    # Training\n",
        "    block_size = 64        # Maximum context length\n",
        "    batch_size = 64        # Batch size\n",
        "    learning_rate = 3e-4   # Learning rate\n",
        "    max_iters = 3000       # Training iterations\n",
        "    eval_interval = 300    # Evaluate every N iterations\n",
        "    eval_iters = 100       # Number of iterations for evaluation\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR0RtnS0eXaV"
      },
      "source": [
        "## Data: Choose Your Dataset\n",
        "\n",
        "Select one of the following datasets by uncommenting the corresponding option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "x_tHC_aheXaV"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 1: TinyStories (Recommended - Modern, Simple English)\n",
        "# ============================================================\n",
        "# # Download a subset of TinyStories dataset\n",
        "# print(\"Downloading TinyStories dataset...\")\n",
        "# url = 'https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "\n",
        "# # Read only first ~1MB (similar to Shakespeare size)\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read(1_000_000)  # Read first 1 million characters\n",
        "\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JsKL3PKueXaV"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 2: Shakespeare (Classic - Early Modern English)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Shakespeare instead:\n",
        "\n",
        "# print(\"Downloading Shakespeare dataset...\")\n",
        "# url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "#\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read()\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Y9BUMz4xeXaW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Python code dataset...\n"
          ]
        },
        {
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDownloading Python code dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m url = \u001b[33m'\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/karpathy/char-rnn/master/data/linux/input.txt\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdataset.txt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     11\u001b[39m     text = f.read(\u001b[32m1_000_000\u001b[39m)  \u001b[38;5;66;03m# Read first 1 million characters\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/urllib/request.py:240\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    241\u001b[39m     headers = fp.info()\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/urllib/request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/urllib/request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/urllib/request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pie_env/lib/python3.12/urllib/request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# OPTION 3: Python Code\n",
        "# ============================================================\n",
        "# Uncomment these lines to train on Python code:\n",
        "\n",
        "print(\"Downloading Python code dataset...\")\n",
        "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/linux/input.txt'\n",
        "urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "\n",
        "with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read(1_000_000)  # Read first 1 million characters\n",
        "\n",
        "print(f'Dataset length: {len(text):,} characters')\n",
        "print(f'\\nFirst 500 characters:')\n",
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74BplMxLeXaW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 4: Modern Novel (e.g., The Adventures of Sherlock Holmes)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Sherlock Holmes:\n",
        "\n",
        "# print(\"Downloading Sherlock Holmes...\")\n",
        "# url = 'https://www.gutenberg.org/files/1661/1661-0.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "#\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read()\n",
        "#\n",
        "# # Remove Project Gutenberg header/footer\n",
        "# start = text.find('I.')\n",
        "# end = text.find('End of the Project Gutenberg')\n",
        "# if start != -1 and end != -1:\n",
        "#     text = text[start:end]\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3rMxw8TeXaW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 5: Wikipedia Article (Simple English Wikipedia)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Wikipedia:\n",
        "\n",
        "# print(\"Downloading Wikipedia dump...\")\n",
        "# # This is a small subset of Simple English Wikipedia\n",
        "# url = 'https://dumps.wikimedia.org/simplewiki/latest/simplewiki-latest-pages-articles.xml.bz2'\n",
        "# # Note: This requires additional processing with packages like mwparserfromhell\n",
        "# # For simplicity, you might want to manually download a few Wikipedia articles as .txt\n",
        "# # Or use a pre-processed Wikipedia dataset\n",
        "#\n",
        "# # For a quick demo, here's a manual approach:\n",
        "# text = \"\"\"Wikipedia is a free online encyclopedia.\n",
        "# [Paste several Wikipedia articles here as plain text]\n",
        "# \"\"\"\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAg1Ed3DeXaW"
      },
      "source": [
        "## Character-Level Tokenization\n",
        "\n",
        "For simplicity, we use character-level tokenization. Each unique character becomes a token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNRV7YDYeXaW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 76 unique characters\n",
            "Characters: \n",
            " !\"',-.01389:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz|–—’“”\n",
            "\n",
            "Original: Hello, world!\n",
            "Encoded: [25, 48, 55, 55, 58, 5, 1, 66, 58, 61, 55, 47, 2]\n",
            "Decoded: Hello, world!\n"
          ]
        }
      ],
      "source": [
        "# Build vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'Vocabulary size: {vocab_size} unique characters')\n",
        "print(f'Characters: {\"\".join(chars)}')\n",
        "\n",
        "# Create character-to-integer and integer-to-character mappings\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encoder: string -> list of integers\n",
        "def encode(s):\n",
        "    return [char_to_idx[c] for c in s]\n",
        "\n",
        "# Decoder: list of integers -> string\n",
        "def decode(ids):\n",
        "    return ''.join([idx_to_char[i] for i in ids])\n",
        "\n",
        "# Test\n",
        "test_str = \"Hello, world!\"\n",
        "encoded = encode(test_str)\n",
        "decoded = decode(encoded)\n",
        "print(f'\\nOriginal: {test_str}')\n",
        "print(f'Encoded: {encoded}')\n",
        "print(f'Decoded: {decoded}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qo1LW5teXaW"
      },
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "Split into train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7dMypRueXaW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded data shape: torch.Size([1000000])\n",
            "Train data: 900,000 tokens\n",
            "Val data: 100,000 tokens\n"
          ]
        }
      ],
      "source": [
        "# Encode the entire dataset\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(f'Encoded data shape: {data.shape}')\n",
        "\n",
        "# Train/validation split (90/10)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(f'Train data: {len(train_data):,} tokens')\n",
        "print(f'Val data: {len(val_data):,} tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3RyRVUFeXaX"
      },
      "source": [
        "## Data Batching\n",
        "\n",
        "Create batches of sequences for training. Each sequence is `block_size` tokens long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVGjjJw6eXaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input batch shape: torch.Size([64, 64])\n",
            "Target batch shape: torch.Size([64, 64])\n",
            "\n",
            "Example sequence:\n",
            "Input:  kly. They said, \"We are sorry, guard. We just wanted to see the \n",
            "Target: ly. They said, \"We are sorry, guard. We just wanted to see the b\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split, config):\n",
        "    \"\"\"\n",
        "    Generate a small batch of data of inputs x and targets y.\n",
        "\n",
        "    Args:\n",
        "        split: 'train' or 'val'\n",
        "        config: Configuration object\n",
        "\n",
        "    Returns:\n",
        "        x: Input sequences [batch_size, block_size]\n",
        "        y: Target sequences [batch_size, block_size]\n",
        "    \"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "\n",
        "    # Randomly select starting positions\n",
        "    ix = torch.randint(len(data) - config.block_size, (config.batch_size,))\n",
        "\n",
        "    # Create input and target sequences\n",
        "    x = torch.stack([data[i:i+config.block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+config.block_size+1] for i in ix])\n",
        "\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# Test batch generation\n",
        "x_batch, y_batch = get_batch('train', config)\n",
        "print(f'Input batch shape: {x_batch.shape}')\n",
        "print(f'Target batch shape: {y_batch.shape}')\n",
        "print(f'\\nExample sequence:')\n",
        "print(f'Input:  {decode(x_batch[0].tolist())}')\n",
        "print(f'Target: {decode(y_batch[0].tolist())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMQUsaI4eXaX"
      },
      "source": [
        "## Model Components\n",
        "\n",
        "Now we build the transformer architecture from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92Q5uwjeXaX"
      },
      "source": [
        "### 1. Multi-Head Attention\n",
        "\n",
        "You've already learned about attention! This is the causal (masked) version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pc_JggyeXaX"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head causal self-attention.\n",
        "\n",
        "    Key difference from your previous class:\n",
        "    - Uses a causal mask to prevent attending to future tokens\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads  # Dimension per head\n",
        "\n",
        "        # Linear projections for Q, K, V (all heads at once)\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        # Output projection\n",
        "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, d_model]\n",
        "\n",
        "        Returns:\n",
        "            Output tensor [batch_size, seq_len, d_model]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # Linear projections\n",
        "        Q = self.W_q(x)  # [batch_size, seq_len, d_model]\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "\n",
        "        # Split into multiple heads and reshape\n",
        "        # [batch_size, seq_len, d_model] -> [batch_size, seq_len, n_heads, d_k]\n",
        "        # -> [batch_size, n_heads, seq_len, d_k]\n",
        "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        # [batch_size, n_heads, seq_len, seq_len]\n",
        "\n",
        "        # Apply causal mask (prevent attending to future tokens)\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device)).bool()\n",
        "        scores = scores.masked_fill(~mask, float('-inf'))\n",
        "\n",
        "        # Apply softmax\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        out = torch.matmul(attn_weights, V)\n",
        "        # [batch_size, n_heads, seq_len, d_k]\n",
        "\n",
        "        # Concatenate heads\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
        "\n",
        "        # Output projection\n",
        "        out = self.W_o(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtzEzEBceXaX"
      },
      "source": [
        "### 2. Feed-Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TegCotmAeXaX"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Position-wise Feed-Forward Network.\n",
        "    Two linear transformations with GELU activation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrXl0BdfeXaX"
      },
      "source": [
        "### 3. Transformer Block\n",
        "\n",
        "Combines attention and feed-forward with residual connections and layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "golNGPNNeXaX"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single transformer block:\n",
        "    - Multi-head attention with residual connection\n",
        "    - Feed-forward network with residual connection\n",
        "    - Layer normalization (pre-norm architecture)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pre-norm architecture (more stable training)\n",
        "        # Attention with residual\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        # Feed-forward with residual\n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1LD_n9eXaX"
      },
      "source": [
        "### 4. Complete Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9pl_dLteXaY"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A minimal GPT-style transformer for next token prediction.\n",
        "\n",
        "    Architecture:\n",
        "    1. Token embeddings + positional embeddings\n",
        "    2. Stack of transformer blocks\n",
        "    3. Layer norm\n",
        "    4. Linear head to predict next token\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Token embeddings\n",
        "        self.token_embedding = nn.Embedding(vocab_size, config.d_model)\n",
        "\n",
        "        # Positional embeddings (learned)\n",
        "        self.pos_embedding = nn.Embedding(config.block_size, config.d_model)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(config.d_model, config.n_heads, config.d_ff, config.dropout)\n",
        "            for _ in range(config.n_layers)\n",
        "        ])\n",
        "\n",
        "        # Final layer norm\n",
        "        self.ln_f = nn.LayerNorm(config.d_model)\n",
        "\n",
        "        # Language modeling head\n",
        "        self.lm_head = nn.Linear(config.d_model, vocab_size, bias=False)\n",
        "\n",
        "        # Weight tying (share weights between token embeddings and lm_head)\n",
        "        self.token_embedding.weight = self.lm_head.weight\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # Report number of parameters\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"Number of parameters: {n_params/1e6:.2f}M\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: Input token indices [batch_size, seq_len]\n",
        "            targets: Target token indices [batch_size, seq_len] (optional)\n",
        "\n",
        "        Returns:\n",
        "            logits: Output logits [batch_size, seq_len, vocab_size]\n",
        "            loss: Cross-entropy loss (if targets provided)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = idx.shape\n",
        "\n",
        "        # Token embeddings\n",
        "        tok_emb = self.token_embedding(idx)  # [batch_size, seq_len, d_model]\n",
        "\n",
        "        # Positional embeddings\n",
        "        pos = torch.arange(0, seq_len, dtype=torch.long, device=idx.device)\n",
        "        pos_emb = self.pos_embedding(pos)  # [seq_len, d_model]\n",
        "\n",
        "        # Add embeddings\n",
        "        x = tok_emb + pos_emb  # Broadcasting happens automatically\n",
        "\n",
        "        # Apply transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Final layer norm\n",
        "        x = self.ln_f(x)\n",
        "\n",
        "        # Language modeling head\n",
        "        logits = self.lm_head(x)  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Compute loss if targets are provided\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            # Reshape for cross-entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits_flat = logits.view(B * T, C)\n",
        "            targets_flat = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Generate new tokens autoregressively.\n",
        "\n",
        "        Args:\n",
        "            idx: Starting sequence [batch_size, seq_len]\n",
        "            max_new_tokens: Number of tokens to generate\n",
        "            temperature: Sampling temperature (higher = more random)\n",
        "            top_k: If set, only sample from top k tokens\n",
        "\n",
        "        Returns:\n",
        "            Generated sequence [batch_size, seq_len + max_new_tokens]\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Crop context if needed (to fit block_size)\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _ = self(idx_cond)\n",
        "\n",
        "            # Focus on last time step\n",
        "            logits = logits[:, -1, :] / temperature  # [batch_size, vocab_size]\n",
        "\n",
        "            # Optionally crop logits to only top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # Append to sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7cO8INdeXaY"
      },
      "source": [
        "## Create Model Instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB1caQEYeXaY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 0.81M\n",
            "GPTModel(\n",
            "  (token_embedding): Embedding(76, 128)\n",
            "  (pos_embedding): Embedding(64, 128)\n",
            "  (blocks): ModuleList(\n",
            "    (0-3): 4 x TransformerBlock(\n",
            "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=128, out_features=76, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "model = GPTModel(vocab_size, config).to(device)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7WpUSDReXaY"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdUzOKiLeXaY"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, config):\n",
        "    \"\"\"\n",
        "    Estimate loss on train and validation sets.\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(config.eval_iters)\n",
        "        for k in range(config.eval_iters):\n",
        "            X, Y = get_batch(split, config)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vPYav8veXaY"
      },
      "source": [
        "## Test Generation Before Training\n",
        "\n",
        "Let's see what the untrained model generates (should be gibberish)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXb0hwe0eXaY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Untrained Model Generation ===\n",
            "\n",
            "-d..—kS.—\n",
            ".m!LLTidjj’mW.d.!mEQ!||8-dxLLm.Smj’L.m-ddKGWF\".Q||x\"||mmNNgdAmKW..|RFA?..m|FfcdwMMmdmL|FddE-Kf|FMWFKQ-WmLKjLM0.?d? .mmmmWm-9XX--dm|www3|LLdwQd.u|FK|u|dmJmQdmFWFc0dd|KKu3WW.W9d-mONWEuQmWhQ-dW\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate from untrained model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=200, temperature=1.0, top_k=10)\n",
        "print('\\n=== Untrained Model Generation ===')\n",
        "print(decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HyKi3XzeXaZ"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "Train for a few thousand iterations. Even this limited training should show improvement!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_c_4azWeXaZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Training for 3000 iterations\n",
            "Evaluating every 300 iterations\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e19da1538176428b9a374ca7a2c4e95b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: train loss 4.3461, val loss 4.3455\n",
            "Step 300: train loss 2.0661, val loss 2.0727\n",
            "Step 600: train loss 1.6012, val loss 1.6109\n",
            "Step 900: train loss 1.3933, val loss 1.3949\n",
            "Step 1200: train loss 1.2643, val loss 1.2783\n",
            "Step 1500: train loss 1.2021, val loss 1.2186\n",
            "Step 1800: train loss 1.1445, val loss 1.1802\n",
            "Step 2100: train loss 1.1004, val loss 1.1357\n",
            "Step 2400: train loss 1.0762, val loss 1.1199\n",
            "Step 2700: train loss 1.0440, val loss 1.0941\n",
            "Step 2999: train loss 1.0301, val loss 1.0759\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "iterations = []\n",
        "\n",
        "print('Starting training...')\n",
        "print(f'Training for {config.max_iters} iterations')\n",
        "print(f'Evaluating every {config.eval_interval} iterations\\n')\n",
        "\n",
        "for iter in tqdm(range(config.max_iters)):\n",
        "    # Evaluate loss periodically\n",
        "    if iter % config.eval_interval == 0 or iter == config.max_iters - 1:\n",
        "        losses = estimate_loss(model, config)\n",
        "        print(f\"Step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        train_losses.append(losses['train'])\n",
        "        val_losses.append(losses['val'])\n",
        "        iterations.append(iter)\n",
        "\n",
        "    # Sample a batch\n",
        "    xb, yb = get_batch('train', config)\n",
        "\n",
        "    # Forward pass\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print('\\nTraining complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD_0vqfleXaZ"
      },
      "source": [
        "## Plot Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqGP8XgTeXaZ"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial train loss: 4.3461\n",
            "Final train loss: 1.0301\n",
            "Improvement: 3.3160\n"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(iterations, train_losses, label='Train Loss', marker='o')\n",
        "plt.plot(iterations, val_losses, label='Validation Loss', marker='s')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f'Initial train loss: {train_losses[0]:.4f}')\n",
        "print(f'Final train loss: {train_losses[-1]:.4f}')\n",
        "print(f'Improvement: {train_losses[0] - train_losses[-1]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nVqySQNeXaZ"
      },
      "source": [
        "## Test Generation After Training\n",
        "\n",
        "Now let's see what the trained model generates!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBZHhCcxeXaZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Trained Model Generation ===\n",
            "\n",
            "<|endoftext|>\n",
            "Once upon a time, there was a new lot. The boy was happy to help her help again. He wanted to be back the slow, but they licked his toys for that the san in the park on his toys. The duck who was to get it. She took it and blied up. One day, a cubilbing. She was time to give the dees in the tree was so shared her.\n",
            "<|endoftext|>\n",
            "One day, a little dog named Tim went to the house, Tim played with his nice. Emma decided to make and spicy fill her together.\n",
            "<|endoftext|>\n",
            "Once upon a toy\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate from trained model\n",
        "model.eval()\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=500, temperature=1.0, top_k=10)\n",
        "print('\\n=== Trained Model Generation ===')\n",
        "print(decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALD6FR6PeXaZ"
      },
      "source": [
        "## Generation with Different Seeds\n",
        "\n",
        "Try starting with different prompts. Adjust these based on your dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1ezJoOZeXaZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Prompt: \"Once upon a time\" ===\n",
            "Once upon a time, there was a little named Sue. She liked to play in the pond and danger. He had a sure little ball in the weops a small tight. The see was still tree again, and they had a lot of flute. They liked to\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"One day, a little\" ===\n",
            "One day, a little girl named Miany. Ben loved to play with the park with her friends. Let's hee would man bag in the water and a came best friendly. They like they always time the big frog.\n",
            "<|endoftext|>\n",
            "One day, a li\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"There was a\" ===\n",
            "There was a tree was not safe.\n",
            "\"Lily asks, Sammy, and the dog!\" The turtle bag and could the work. He said Sam.\n",
            "The bird was very happy. It made the found a big tree and water. How took him to show together, the\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"The girl was\" ===\n",
            "The girl was a cat named Sue. She called Bybe wanted to help him.\n",
            "<|endoftext|>\n",
            "Once upon a time, there was a toy named Tim. Tim was surprised to go to the maght. He was very surprised. He asked her mome and what\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "def generate_with_prompt(prompt, max_new_tokens=300, temperature=0.8, top_k=10):\n",
        "    \"\"\"\n",
        "    Generate text starting from a prompt.\n",
        "    \"\"\"\n",
        "    context = torch.tensor([encode(prompt)], dtype=torch.long, device=device)\n",
        "    generated = model.generate(context, max_new_tokens=max_new_tokens,\n",
        "                             temperature=temperature, top_k=top_k)\n",
        "    return decode(generated[0].tolist())\n",
        "\n",
        "# Choose prompts based on your dataset:\n",
        "\n",
        "# For TinyStories:\n",
        "prompts = [\n",
        "    \"Once upon a time\",\n",
        "    \"One day, a little\",\n",
        "    \"There was a\",\n",
        "    \"The girl was\"\n",
        "]\n",
        "\n",
        "# For Shakespeare:\n",
        "# prompts = [\n",
        "#     \"ROMEO:\\n\",\n",
        "#     \"To be or not to be\",\n",
        "#     \"First Citizen:\\n\",\n",
        "#     \"The king\"\n",
        "# ]\n",
        "\n",
        "# For Python code:\n",
        "# prompts = [\n",
        "#     \"def \",\n",
        "#     \"import \",\n",
        "#     \"class \",\n",
        "#     \"for i in\"\n",
        "# ]\n",
        "\n",
        "# For Sherlock Holmes:\n",
        "# prompts = [\n",
        "#     \"Sherlock Holmes\",\n",
        "#     \"The detective\",\n",
        "#     \"Watson said\",\n",
        "#     \"It was a\"\n",
        "# ]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f'\\n=== Prompt: \"{prompt}\" ===')\n",
        "    generated_text = generate_with_prompt(prompt, max_new_tokens=200)\n",
        "    print(generated_text)\n",
        "    print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcbOR0dteXaZ"
      },
      "source": [
        "## Temperature and Top-K Effects\n",
        "\n",
        "Experiment with different generation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PATeFcuCeXaZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Low Temperature (0.5) - More focused ===\n",
            "Once upon a time, there was a started in the park. He loved to play with her family. He was so happy. He took the bird and said, \"Thank you, we can me to get the stic\n",
            "\n",
            "=== Medium Temperature (1.0) - Balanced ===\n",
            "Once upon a time, there was a new friends.\n",
            "The moral old man around him and happy.\n",
            "The fly played, Tim found and her friends. They helped that they all cat had lots.\"\n",
            "\n",
            "=== High Temperature (1.5) - More random ===\n",
            "Once upon a time, there little g named Sue. She loved time a butterfly. The boy learded the sand.\n",
            "Sue pecied, the tree day brave for thow. But thelpned talked, and so\n"
          ]
        }
      ],
      "source": [
        "# Choose a prompt from your dataset:\n",
        "prompt = \"Once upon a time\"  # For TinyStories\n",
        "# prompt = \"ROMEO:\\n\"  # For Shakespeare\n",
        "# prompt = \"def \"  # For Python code\n",
        "# prompt = \"Sherlock Holmes\"  # For Sherlock Holmes\n",
        "\n",
        "print(\"=== Low Temperature (0.5) - More focused ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=0.5, top_k=10))\n",
        "\n",
        "print(\"\\n=== Medium Temperature (1.0) - Balanced ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=1.0, top_k=10))\n",
        "\n",
        "print(\"\\n=== High Temperature (1.5) - More random ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=1.5, top_k=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vguoqWQ1eXaZ"
      },
      "source": [
        "## Analysis: What Did We Learn?\n",
        "\n",
        "Even with this minimal training:\n",
        "1. **Structure**: The model learns basic text structure (words, punctuation, capitalization)\n",
        "2. **Patterns**: It picks up on common patterns in the data\n",
        "   - TinyStories: narrative structure, character actions\n",
        "   - Shakespeare: dialogue format, character names\n",
        "   - Python code: syntax, indentation, function structure\n",
        "3. **Context**: The causal attention allows it to use context from previous tokens\n",
        "4. **Limitations**: It's not perfect - longer coherence requires much more training\n",
        "\n",
        "**Key Architecture Points:**\n",
        "- **Decoder-only**: Unlike encoder-decoder models for translation, this is decoder-only (like GPT)\n",
        "- **Causal attention**: The mask ensures we only attend to past tokens\n",
        "- **Next token prediction**: Simple but powerful objective\n",
        "- **Scalability**: This same architecture scales to billions of parameters (GPT-3, GPT-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzmVKYZheXaZ"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "To improve this model further, try one or multiple of the following:\n",
        "1. Train for more iterations (10k-50k)\n",
        "2. Increase model size (more layers, larger d_model)\n",
        "3. Combine datasets together to have more text (be careful of style differences)\n",
        "4. Add learning rate scheduling\n",
        "5. Modify the optimizer and hyperparameters\n",
        "6. Implement gradient clipping\n",
        "7. Try different tokenization (BPE instead of character-level)\n",
        "8. Add dropout for better regularization\n",
        "9. Experiment with different attention patterns (e.g., Flash Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVFo9a-HeXaa"
      },
      "source": [
        "## Save Model (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdQWTUaleXaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to minimal_transformer_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# Save model checkpoint\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'config': config,\n",
        "    'vocab_size': vocab_size,\n",
        "    'char_to_idx': char_to_idx,\n",
        "    'idx_to_char': idx_to_char,\n",
        "}, 'minimal_transformer_checkpoint.pt')\n",
        "\n",
        "print('Model saved to minimal_transformer_checkpoint.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l1wz2CPeXaa"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we built a minimal transformer from scratch:\n",
        "- Character-level tokenization\n",
        "- Causal multi-head attention\n",
        "- Position-wise feed-forward networks\n",
        "- Residual connections and layer normalization\n",
        "- Next token prediction training\n",
        "- Autoregressive generation\n",
        "\n",
        "This architecture is the foundation of modern LLMs like GPT!\n",
        "\n",
        "**Questions to consider:**\n",
        "1. Why is causal masking necessary for language generation?\n",
        "2. What would happen without positional embeddings?\n",
        "3. How does temperature affect generation quality?\n",
        "4. What are the tradeoffs between character-level and subword tokenization?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pie_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
